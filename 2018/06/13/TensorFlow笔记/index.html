<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>TensorFlow笔记 | Renewing</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="神经网络神经网络的基本概念 张量是多维数组（列表），用‘阶’表示张量的维度 TensorFlow的数据类型有tf.float32、tf.int32等 计算图：是承载一个或多个计算节点的一张图，只搭建网络，不运算  12345import tensorflow as tfx = tf.constant([[1.0, 2.0]])w = tf.constant([[3.0],[4.0]])y = tf">
<meta name="keywords" content="深度学习,TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow笔记">
<meta property="og:url" content="http://www.wuxiaochun.cn/2018/06/13/TensorFlow笔记/index.html">
<meta property="og:site_name" content="Renewing">
<meta property="og:description" content="神经网络神经网络的基本概念 张量是多维数组（列表），用‘阶’表示张量的维度 TensorFlow的数据类型有tf.float32、tf.int32等 计算图：是承载一个或多个计算节点的一张图，只搭建网络，不运算  12345import tensorflow as tfx = tf.constant([[1.0, 2.0]])w = tf.constant([[3.0],[4.0]])y = tf">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-06-13T03:03:16.662Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow笔记">
<meta name="twitter:description" content="神经网络神经网络的基本概念 张量是多维数组（列表），用‘阶’表示张量的维度 TensorFlow的数据类型有tf.float32、tf.int32等 计算图：是承载一个或多个计算节点的一张图，只搭建网络，不运算  12345import tensorflow as tfx = tf.constant([[1.0, 2.0]])w = tf.constant([[3.0],[4.0]])y = tf">
  
    <link rel="alternative" href="/atom.xml" title="Renewing" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">

</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/img/youyou.jpg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Renewing</a></h1>
		</hgroup>

		
		<p class="header-subtitle">此心安处，便是吾乡。</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/archives">文章归档</a></li>
				        
							<li><a href="/categories/machine-learning">机器学习</a></li>
				        
							<li><a href="/categories/deep-learning">深度学习</a></li>
				        
							<li><a href="/categories/signal-processing">信号处理</a></li>
				        
							<li><a href="/categories/mind-palace">随笔</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/Renewing" title="github">github</a>
					        
								<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/zs-renewing/activities" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="mailto:wxc19966@pku.edu.cn" title="mail">mail</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/TensorFlow/" style="font-size: 10px;">TensorFlow</a> <a href="/tags/信号处理/" style="font-size: 10px;">信号处理</a> <a href="/tags/卷积序列/" style="font-size: 10px;">卷积序列</a> <a href="/tags/机器学习/" style="font-size: 20px;">机器学习</a> <a href="/tags/树模型/" style="font-size: 10px;">树模型</a> <a href="/tags/深度学习/" style="font-size: 20px;">深度学习</a> <a href="/tags/特征处理/" style="font-size: 10px;">特征处理</a> <a href="/tags/特征工程/" style="font-size: 10px;">特征工程</a> <a href="/tags/随笔/" style="font-size: 10px;">随笔</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">微电子码农，PKU在读，机器学习菜鸟。此博客日常分享技术心得，抽风吐槽心情。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Renewing</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img src="/img/youyou.jpg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Renewing</h1>
			</hgroup>
			
			<p class="header-subtitle">此心安处，便是吾乡。</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/archives">文章归档</a></li>
		        
					<li><a href="/categories/machine-learning">机器学习</a></li>
		        
					<li><a href="/categories/deep-learning">深度学习</a></li>
		        
					<li><a href="/categories/signal-processing">信号处理</a></li>
		        
					<li><a href="/categories/mind-palace">随笔</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/Renewing" title="github">github</a>
			        
						<a class="zhihu" target="_blank" href="https://www.zhihu.com/people/zs-renewing/activities" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="mailto:wxc19966@pku.edu.cn" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-TensorFlow笔记" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2018/06/13/TensorFlow笔记/" class="article-date">
  	<time datetime="2018-06-13T02:58:53.000Z" itemprop="datePublished">2018-06-13</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      TensorFlow笔记
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li></ul>
	</div>

        
	<div class="article-category tagcloud">
	<a class="article-category-link" href="/categories/deep-learning/">深度学习</a>
	</div>


        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h1><h2 id="神经网络的基本概念"><a href="#神经网络的基本概念" class="headerlink" title="神经网络的基本概念"></a>神经网络的基本概念</h2><ol>
<li>张量是多维数组（列表），用‘阶’表示张量的维度</li>
<li>TensorFlow的数据类型有tf.float32、tf.int32等</li>
<li>计算图：是承载一个或多个计算节点的一张图，只搭建网络，不运算</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x = tf.constant([[<span class="number">1.0</span>, <span class="number">2.0</span>]])</span><br><span class="line">w = tf.constant([[<span class="number">3.0</span>],[<span class="number">4.0</span>]])</span><br><span class="line">y = tf.matmul(x,w)</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>
<pre><code>Tensor(&quot;MatMul_3:0&quot;, shape=(1, 1), dtype=float32)
</code></pre><p>可以看到，print的结构显示y是一个张量，只搭建承载计算过程的计算图，并没有运算。<br><a id="more"></a></p>
<ol start="4">
<li>会话：执行计算图中的节点运算<br>用with结构实现，语法如下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(y))</span><br></pre></td></tr></table></figure>
<pre><code>[[11.]]
</code></pre><h2 id="神经网络的搭建"><a href="#神经网络的搭建" class="headerlink" title="神经网络的搭建"></a>神经网络的搭建</h2><ol>
<li>准备数据集，提取特征，作为输入喂给NN</li>
<li>搭建NN结构，从输入到输出（先搭建计算图，再用会话执行）<br> （NN前向传播算法–&gt;计算输出）</li>
<li>大量特征数据喂给NN，迭代优化NN参数<br> （NN反向传播算法–&gt;优化参数训练模型）</li>
<li>使用训练好的模型预测和分类</li>
</ol>
<h3 id="前向传播的tensorflow描述"><a href="#前向传播的tensorflow描述" class="headerlink" title="前向传播的tensorflow描述"></a>前向传播的tensorflow描述</h3><p>变量初始化、计算图节点运算都要用会话（with结构）实现</p>
<pre><code>with tf.Session() as sess:

    sess.run()
</code></pre><p>变量初始化：在sess.run函数中用tf.global_variables_initializer()汇总所有待优化变量</p>
<pre><code>init_op = tf.global_variables_initializer()

sess.run(init_op)
</code></pre><p>计算图节点运算：在sess.run函数中写入待运算的节点</p>
<pre><code>sess.run(y)
</code></pre><p>用tf.placeholder占位，在sess.run函数中用feed_dict喂数据<br>喂一组数据：</p>
<pre><code>x = tf.placeholder(tf.float32, shape=(1,2))

sess.run(y,feed_dict={x: [[0.5,0.6]]})
</code></pre><p>喂多组数据：</p>
<pre><code>x = tf.placeholder(tf.float32, shape=(None,2))

sess.run(y,feed_dict={x: [[0.5,0.6]],[[0.1,0.5]],[[0.4,0.2]]，[[0.8,0.7]]})
</code></pre><h3 id="反向传播的tensorflow描述"><a href="#反向传播的tensorflow描述" class="headerlink" title="反向传播的tensorflow描述"></a>反向传播的tensorflow描述</h3><ul>
<li><p>反向传播：训练模型参数，在所有参数上用梯度下降，使NN模型在训练数据上的损失函数最小</p>
</li>
<li><p>损失函数（loss）：计算得到的预测值y与已知y_的差距</p>
</li>
<li><p>均方误差MSE：常用的损失函数计算方法，是求前向传播计算结果与已知答案之差的平方再求平均。</p>
<p>  loss_mse = tf.reduce_mean(tf.square(y_ - y)) </p>
</li>
<li><p>反向传播训练方法：以减小 loss 值为优化目标，有梯度下降、momentum 优化器、adam 优化器等优化方法。</p>
<p>  train_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)</p>
<p>  train_step=tf.train.MomentumOptimizer(learning_rate, momentum).minimize(loss)</p>
<p>  train_step=tf.train.AdamOptimizer(learning_rate).minimize(loss)</p>
</li>
<li><p>学习率：决定每次参数更新的幅度。</p>
</li>
</ul>
<h2 id="神经网络优化"><a href="#神经网络优化" class="headerlink" title="神经网络优化"></a>神经网络优化</h2><ul>
<li>交叉熵(Cross Entropy)：表示两个概率分布之间的距离。交叉熵越大，两个概率分布距离越远，两个概率分布越相异；交叉熵越小，两个概率分布距离越近，两个概率分布越相似。交叉熵计算公式：𝐇(𝐲_ , 𝐲) = −∑𝐲_ ∗ 𝒍𝒐𝒈 𝒚</li>
</ul>
<p>用 Tensorflow 函数表示为</p>
<pre><code>ce= -tf.reduce_mean(y_* tf.log(tf.clip_by_value(y, 1e-12, 1.0))) 
</code></pre><ul>
<li>softmax函数：将 n 分类的 n 个输出（y1,y2…yn）变为满足以下概率分布要求的函数。</li>
</ul>
<p>在 Tensorflow 中，一般让模型的输出经过 sofemax 函数，以获得输出分类的概率分布，再与标准<br>答案对比，求出交叉熵，得到损失函数，用如下函数实现：</p>
<pre><code>ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))

cem = tf.reduce_mean(ce)
</code></pre><ul>
<li>学习率 learning_rate：表示了每次参数更新的幅度大小。学习率过大，会导致待优化的参数在最小值附近波动，不收敛；学习率过小，会导致待优化的参数收敛缓慢。在训练过程中，参数的更新向着损失函数梯度下降的方向。</li>
</ul>
<p>参数的更新公式为：</p>
<pre><code>𝒘𝒏+𝟏 = 𝒘𝒏 − 𝒍𝒆𝒂𝒓𝒏𝒊𝒏𝒈_𝒓𝒂𝒕𝒆delta
</code></pre><ul>
<li>指数衰减学习率：学习率随着训练轮数变化而动态更新</li>
</ul>
<p>用 Tensorflow 的函数表示为：</p>
<pre><code>global_step = tf.Variable(0, trainable=False)

learning_rate = tf.train.exponential_decay(
LEARNING_RATE_BASE,
global_step,
LEARNING_RATE_STEP, LEARNING_RATE_DECAY,
staircase=True/False)
</code></pre><p>   注：staircase为True时，表示global_step/learning rate step取整数，学习率阶梯型衰减</p>
<pre><code>staircase为False时，学习率是一条平滑下降的曲线
</code></pre><ul>
<li>滑动平均：记录了一段时间内模型中所有参数 w 和 b 各自的平均值。利用滑动平均值可以增强模型的泛化能力。</li>
</ul>
<p>滑动平均值（影子）计算公式：</p>
<p>影子 = 衰减率 <em> 影子 +（1 - 衰减率）</em> 参数</p>
<p>其中，衰减率 = 𝐦𝐢𝐧 {𝑴𝑶𝑽𝑰𝑵𝑮𝑨𝑽𝑬𝑹𝑨𝑮𝑬𝑫𝑬𝑪𝑨𝒀,(𝟏+轮数)/(𝟏𝟎+轮数)}，影子初值=参数初值   </p>
<p>用 Tensorflow 函数表示为：</p>
<pre><code>ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY，global_step)
</code></pre><p>其中，MOVING_AVERAGE_DECAY 表示滑动平均衰减率，一般会赋接近 1 的值，global_step 表示当前训练了多少轮。</p>
<pre><code>ema_op = ema.apply(tf.trainable_variables())
</code></pre><p>其中，ema.apply()函数实现对括号内参数求滑动平均，tf.trainable_variables()函数实现把所有待训练参数汇总为列表。</p>
<pre><code>with tf.control_dependencies([train_step, ema_op]):
     train_op = tf.no_op(name=&apos;train&apos;) 
</code></pre><ul>
<li><p>过拟合：神经网络模型在训练数据集上的准确率较高，在新的数据进行预测或分类时准确率较低，说明模型的泛化能力差。 </p>
</li>
<li><p>正则化：在损失函数中给每个参数 w 加上权重，引入模型复杂度指标，从而抑制模型噪声，减小过拟合。 </p>
</li>
</ul>
<p>正则化计算方法：<br>① L1 正则化： 𝒍𝒐𝒔𝒔𝑳𝟏 = ∑𝒊|𝒘𝒊|</p>
<p>用 Tensorflow 函数表示:</p>
<pre><code>loss(w) = tf.contrib.layers.l1_regularizer(REGULARIZER)(w)
</code></pre><p>② L2 正则化： 𝒍𝒐𝒔𝒔𝑳𝟐 = ∑𝒊|𝒘𝒊|^𝟐</p>
<p>用 Tensorflow 函数表示:</p>
<pre><code>loss(w) = tf.contrib.layers.l2_regularizer(REGULARIZER)(w)
</code></pre><p>用 Tensorflow 函数实现正则化：</p>
<pre><code>tf.add_to_collection(&apos;losses&apos;, tf.contrib.layers.l2_regularizer(regularizer)(w)
loss = cem + tf.add_n(tf.get_collection(&apos;losses&apos;)) 
</code></pre><p>利用L1经过训练后，会让权重得到稀疏解，即权重中的一部分项为0，这种作用相当于对原始数据进行了特征选择；利用L2进行训练后，会让权重更趋于0，但不会得到稀疏结，这样做可以避免某些权重过大；两种正则做法都可以减轻过拟合，使训练结果更加具有鲁棒性。</p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2018/06/26/改善深层神经网络-Initialization/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          改善深层神经网络-Initialization
        
      </div>
    </a>
  
  
    <a href="/2018/06/11/梯度提升树-GBDT-概述及sklearn调参/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">梯度提升树(GBDT)概述及sklearn调参</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>








</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2018 Renewing
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
<span id="busuanzi_container_page_pv">
  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</span>
</footer>

    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: ,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>